// ============================================
// CHAPTERS/04-METHODOLOGY.TYP
// ============================================

= Methodology

== Research Design

This study adopts an exploratory, computational research design grounded in pattern recognition and machine learning to address the stated research objectives. The design is exploratory because it seeks to uncover latent antimicrobial resistance (AMR) structures that are not explicitly defined by existing categorical labels, rather than testing predefined hypotheses or establishing causal relationships. It is computational in nature because the primary contribution of the study lies in the design, implementation, and evaluation of a data-driven analytical framework for resistance pattern discovery and validation.

The research design integrates unsupervised learning for resistance structure discovery with supervised learning used exclusively as an external validation mechanism. Unsupervised methods are employed to identify resistance patterns based solely on phenotypic similarity in antimicrobial susceptibility testing (AST) data, without incorporating biological, environmental, or geographic labels during the discovery phase. Supervised learning is subsequently applied to assess the discriminative capacity and robustness of the discovered patterns, thereby addressing the limitations of unsupervised clustering when used in isolation.

The methodological strategy follows a staged, leakage-aware pipeline consisting of: (1) data preprocessing and feature engineering, (2) unsupervised resistance pattern discovery, (3) supervised validation, (4) integrated system design, and (5) quantitative evaluation. Throughout the study, strict separation is maintained between pattern discovery and interpretation to prevent information leakage and circular reasoning. The study is associational and descriptive in scope; no biological mechanisms, epidemiological transmission pathways, or clinical outcomes are inferred.

== Data Source and Description

=== Dataset Provenance

The dataset analyzed in this study was generated by the *INOHAC AMR Project Two* research team as part of an environmental antimicrobial resistance surveillance initiative. The present study did not involve primary sampling or laboratory experimentation. All analyses were conducted as a *secondary analysis* of phenotypic AST data collected by the source project.

The dataset comprises AST results for bacterial isolates obtained from environmental and aquaculture-associated sources across three geographic regions in the Philippines. The geographic distribution of isolates is summarized in *Table 4.1*.

#figure(
  table(
    columns: 3,
    table.header[*Region*][*National Code*][*Local Sites*],
    [Eastern Visayas (Ormoc)], [O], [Alegria, Larrazabal],
    [Central Luzon (Pampanga)], [P], [San Gabriel, San Roque],
    [BARMM (Marawi)], [M], [APMC, Dayawan, Gadongan, Tuca Kialdan],
  ),
  caption: [Geographic Distribution of Isolates],
) <tab:geographic-distribution>

=== Sample Source Categories

Isolates originated from environmental matrices representing the *Water–Fish interface* within the broader Water–Fish–Human nexus. These source categories capture exposure pathways relevant to environmental AMR dissemination and were used exclusively as contextual metadata during interpretation. Source categories are listed in *Table 4.2*.

#figure(
  table(
    columns: 3,
    table.header[*Source Code*][*Source Type*][*Description*],
    [DW], [Drinking Water], [Community water sources],
    [LW], [Lake Water], [Natural water bodies],
    [RW], [River Water], [Flowing water systems],
    [EWU], [Effluent Water (Untreated)], [Hospital or facility discharge (Human interface)],
    [EWT], [Effluent Water (Treated)], [Processed effluent discharge (Human interface)],
    [FB, FG, FT, FK], [Fish], [Banak, Gusaw, Tilapia, Kaolang],
  ),
  caption: [Sample Source Categories],
) <tab:sample-source-categories>

*Note:* While direct human clinical isolates are not included, effluent water samples (EWU, EWT) represent the anthropogenic component of the nexus, capturing resistance patterns potentially influenced by human antibiotic use and healthcare facility discharge.

=== Isolate Identification Convention

Each isolate was assigned a structured alphanumeric identifier encoding species, geographic origin, source type, replicate number, and colony number using the format:

```
[Species Prefix]_[Region][Site][Source][Replicate]C[Colony]
```

This convention enables systematic metadata parsing while preserving traceability throughout the analytical pipeline.

=== Antimicrobial Panel

Phenotypic AST data were generated using a panel of *22 antibiotics spanning 12 antimicrobial classes*, including an ESBL screening indicator. The antimicrobial panel is summarized in *Table 4.3*.

#figure(
  table(
    columns: 2,
    table.header[*Antimicrobial Class*][*Antibiotics*],
    [Penicillins], [Ampicillin],
    [β-lactam/β-lactamase inhibitors], [Amoxicillin/Clavulanic Acid],
    [Cephalosporins (1st gen.)], [Cefalexin, Cefalotin],
    [Cephalosporins (3rd/4th gen.)], [Cefpodoxime, Cefotaxime, Cefovecin, Ceftiofur],
    [Advanced cephalosporins], [Ceftaroline, Ceftazidime/Avibactam],
    [Carbapenems], [Imipenem],
    [Aminoglycosides], [Amikacin, Gentamicin, Neomycin],
    [Quinolones / Fluoroquinolones], [Nalidixic Acid, Enrofloxacin, Marbofloxacin, Pradofloxacin],
    [Tetracyclines], [Doxycycline, Tetracycline],
    [Nitrofurans], [Nitrofurantoin],
    [Phenicols], [Chloramphenicol],
    [Folate pathway inhibitors], [Trimethoprim/Sulfamethoxazole],
    [Resistance indicator], [ESBL screening],
  ),
  caption: [Antimicrobial Panel Composition],
) <tab:antimicrobial-panel>

== Phase 1: Data Preprocessing and Feature Engineering

The objective of this phase is to transform heterogeneous raw antimicrobial susceptibility testing (AST) records into a structured numerical form that supports similarity-based analysis while preserving biologically meaningful resistance information. All preprocessing decisions were explicitly parameterized to ensure reproducibility and to prevent information leakage in downstream analyses.

=== Data Ingestion and Harmonization

Raw phenotypic AST data were consolidated from multiple source files provided by the INOHAC–Project 2. These files, supplied as comma-separated value (CSV) datasets corresponding to different collection sites, were integrated into a single unified dataset.

The ingestion process included the following steps:

- *Schema harmonization:* Column names, data types, and value encodings were standardized across source files to ensure structural consistency.
- *Metadata extraction:* Structured isolate identifiers were parsed to extract contextual variables such as geographic region, local site, source category, replicate number, and colony number.
- *Duplicate resolution:* Duplicate isolate records were identified and removed to ensure a one-to-one correspondence between isolates and resistance profiles.

This step ensured that all downstream analyses operated on a coherent and internally consistent dataset.

=== Data Quality Filtering

To ensure sufficient data completeness for reliable pattern recognition, threshold-based filtering criteria were applied at both the antibiotic and isolate levels.

- *Antibiotic-level filtering:* Antibiotics tested on fewer than *70% of isolates* were excluded to ensure adequate representation across resistance profiles.
- *Isolate-level filtering:* Isolates with more than *30% missing susceptibility values* were removed to avoid excessive reliance on imputation.

These thresholds balance data retention with analytical reliability and are consistent with exploratory machine learning practices applied to high-dimensional biological data. All thresholds were fixed prior to analysis to prevent post-hoc optimization.

=== Resistance Encoding

Phenotypic AST outcomes recorded as categorical values—Susceptible (S), Intermediate (I), and Resistant (R)—were converted into ordinal numerical representations to support quantitative analysis.

#figure(
  table(
    columns: 3,
    table.header[*Phenotype*][*Encoded Value*][*Interpretation*],
    [Susceptible (S)], [0], [No resistance observed],
    [Intermediate (I)], [1], [Reduced susceptibility],
    [Resistant (R)], [2], [Clinical resistance],
  ),
  caption: [Ordinal Encoding of Phenotypic AST Results],
) <tab:resistance-encoding>

This ordinal encoding preserves the progressive nature of resistance severity while enabling distance-based computations.

=== Missing Value Imputation

Following threshold-based exclusion, remaining missing susceptibility values were imputed using *median imputation*, applied independently to each antibiotic feature:

$
hat(x)_(i,j) = "median"({x_(k,j) | x_(k,j) "is observed"})
$

where $hat(x)_(i,j)$ is the imputed resistance value for isolate $i$ and antibiotic $j$, and $x_(k,j)$ represents observed resistance values for antibiotic $j$.

Median imputation is robust to outliers and preserves the ordinal nature of resistance data. Alternative strategies such as mean or mode imputation were considered; however, the median provides a conservative central estimate suitable for exploratory pattern recognition.

=== Derived Resistance Feature Computation

To support downstream interpretation and epidemiological contextualization, several derived resistance descriptors were computed. These features were *not included as inputs* to unsupervised clustering to prevent bias during pattern discovery.

==== Multiple Antibiotic Resistance (MAR) Index

The MAR index quantifies the proportion of antibiotics to which an isolate exhibits resistance:

$
"MAR" = a / b
$

where $a$ is the number of antibiotics for which resistance is observed (encoded value = 2), and $b$ is the total number of antibiotics tested for the isolate.

*Interpretation:*

- MAR ≤ 0.2: Low-risk source
- MAR > 0.2: High-risk source, indicative of antibiotic selection pressure

(Reference: Krumperman, 1983)

==== Resistant Classes Count

The breadth of resistance across antimicrobial classes was computed as:

$
"Resistant Classes" = |{c | exists a in c, "resistance"(a) = "true"}|
$

where $c$ denotes an antimicrobial class and $a$ denotes an antibiotic belonging to that class.

This metric captures class-level resistance diversity rather than resistance to individual agents.

==== Multidrug Resistance (MDR) Classification

An isolate was classified as multidrug-resistant (MDR) if resistance was observed in *three or more antimicrobial classes*, consistent with established definitions:

$
"MDR" = cases(
  1\, & "if Resistant Classes" >= 3,
  0\, & "otherwise"
)
$

(Reference: Magiorakos et al., 2012)

=== Feature–Metadata Separation

To prevent *information leakage* and circular reasoning, the analysis-ready dataset was explicitly partitioned into two components:

- *Feature Matrix ($bold(X)$):* Encoded resistance values for the 22 antibiotics, used exclusively for unsupervised clustering and supervised validation.
- *Metadata Matrix ($bold(M)$):* Contextual variables (e.g., region, site, species, source category, MDR status), reserved solely for post-discovery interpretation.

This separation ensures that resistance patterns are discovered strictly from phenotypic similarity and are not influenced by external labels or contextual information.

=== Phase 1 Output Summary

The output of Phase 1 consists of:

- Analysis-ready resistance feature matrix with encoded susceptibility values
- Derived resistance indicators (MAR, Resistant Classes, MDR status)
- Separated metadata matrix for post-hoc interpretation
- Data quality documentation including filtering statistics

== Phase 2: Unsupervised Structure Discovery

The objective of this phase is to identify latent resistance structures based solely on phenotypic similarity in antimicrobial susceptibility profiles, without incorporating predefined biological, environmental, or geographic labels. All analyses in this phase operate exclusively on the resistance feature matrix produced in Phase 1.

=== Clustering Algorithm Selection

*Hierarchical Agglomerative Clustering (HAC)* was selected as the primary unsupervised learning method due to the following properties:

- *Exploratory suitability:* HAC does not require prior specification of the number of clusters, aligning with the study's objective of discovering latent structure rather than fitting predefined categories.
- *Multi-scale structure discovery:* The hierarchical representation enables examination of resistance patterns at multiple levels of granularity.
- *Interpretability:* Dendrograms provide transparent visualization of cluster formation and merge decisions.
- *Minimal structural assumptions:* HAC does not impose assumptions regarding cluster shape or distribution.

These characteristics make HAC appropriate for exploratory pattern recognition in high-dimensional resistance data.

=== Distance Metric

Euclidean distance was used as the primary measure of dissimilarity between resistance profiles:

$
d(x, y) = sqrt(sum_(i=1)^n (x_i - y_i)^2)
$

where $x$ and $y$ are resistance vectors for two isolates and $n$ is the number of antibiotics.

*Justification:* Euclidean distance preserves proportional differences introduced by ordinal resistance encoding (S = 0, I = 1, R = 2) and is required for variance-based linkage methods such as Ward's criterion. Given the 22-dimensional feature space where the number of features is substantially smaller than the sample size, Euclidean distance remains effective without dimensionality reduction.

=== Linkage Method

Ward's *minimum variance linkage method* was used to guide cluster merging:

$
Delta(A, B) = (n_A n_B) / (n_A + n_B) norm(c_A - c_B)^2
$

where:

- $n_A$ and $n_B$ denote the sizes of clusters $A$ and $B$,
- $c_A$ and $c_B$ represent their respective centroids.

Ward's method minimizes the increase in total within-cluster variance at each merge step, producing compact and relatively balanced clusters. This property is advantageous for identifying resistance phenotypes that are internally coherent and externally separable in feature space.

=== Determination of the Number of Clusters

The optimal number of clusters was determined using a *data-driven, multi-criteria approach* combining quantitative metrics with practical constraints.

==== Silhouette Analysis

Cluster cohesion and separation were evaluated using the silhouette score:

$
s(i) = (b(i) - a(i)) / max(a(i), b(i))
$

where:

- $a(i)$ is the mean intra-cluster distance for isolate $i$,
- $b(i)$ is the mean distance to the nearest neighboring cluster.

Higher silhouette values indicate better-defined cluster structure. The average silhouette score across all isolates was computed for cluster solutions ranging from $k = 2$ to $k = 10$.

==== Within-Cluster Sum of Squares (WCSS)

Cluster compactness was assessed using the within-cluster sum of squares:

$
"WCSS" = sum_(k=1)^K sum_(x in C_k) norm(x - mu_k)^2
$

where $C_k$ denotes cluster $k$ and $mu_k$ its centroid. The elbow method was used to identify diminishing returns in compactness as the number of clusters increased.

==== Practical Constraints

To ensure analytical stability and interpretability, additional constraints were applied:

- *Minimum cluster size:* At least *20 isolates per cluster*
- *Interpretability:* Preference for solutions that balance granularity with conceptual clarity, avoiding over-fragmentation

The final cluster solution was selected based on convergence across these criteria rather than optimization of a single metric.

=== Cluster Stability Assessment

The robustness of the discovered clustering structure was evaluated through *stability analysis* using two complementary approaches.

==== Alternative Configuration Comparison

Agreement between clustering solutions obtained using different distance metrics (Euclidean, Manhattan) was quantified using the *Adjusted Rand Index (ARI)*:

$
"ARI" = ("RI" - E["RI"]) / (max("RI") - E["RI"])
$

where RI is the Rand Index and $E["RI"]$ is its expected value under random labeling, and $max("RI")$ is the maximum possible Rand Index.

==== Bootstrap Stability

Cluster membership stability was assessed through bootstrap resampling:

1. Resample 80% of isolates with replacement ($n = 100$ iterations)
2. Re-cluster each bootstrap sample using identical parameters
3. Compute Jaccard similarity between original and bootstrap cluster assignments

Higher ARI and Jaccard values indicate greater stability and robustness of the clustering structure, suggesting that identified resistance patterns are not artifacts of specific parameter choices.

=== Cluster-Level Profile Characterization

For each identified cluster, a *resistance profile* was computed summarizing the dominant phenotypic characteristics:

- *Mean resistance score* per antibiotic (0–2 scale)
- *Resistance prevalence* (proportion of isolates with R classification per antibiotic)
- *Class-level resistance summary* aggregating across antimicrobial categories

These profiles enable qualitative characterization of each cluster's resistance signature.

=== Phase 2 Output Summary

The output of this phase consists of:

- Final cluster assignments for each isolate
- Hierarchical linkage matrices and dendrograms
- Cluster-level resistance profiles summarizing dominant phenotypic patterns
- Stability metrics (ARI, Jaccard coefficients)

These outputs form the basis for supervised validation and interpretation, while remaining independent of external biological or contextual labels during discovery.

== Phase 3: Supervised Validation

Supervised learning models were used solely to validate the discriminative capacity of the discovered resistance patterns. This phase implements leakage-safe train–test splitting, macro-averaged evaluation metrics, confusion matrix analysis, feature importance extraction, and cross-seed stability checks.

=== Classification Tasks

Two supervised classification tasks were designed to assess whether resistance patterns align with known biological categories:

#figure(
  table(
    columns: 3,
    table.header[*Task*][*Target Variable*][*Purpose*],
    [Species Discrimination], [Bacterial species], [Assess if resistance fingerprints distinguish species],
    [MDR Classification], [MDR status (0/1)], [Validate resistance-MDR relationship],
  ),
  caption: [Supervised Classification Tasks],
) <tab:supervised-classification-tasks>

=== Leakage-Safe Data Splitting

To prevent information leakage between training and evaluation phases, the dataset was first partitioned into *training (80%) and test (20%) subsets* using stratified sampling to preserve class distributions. *Train–test splitting was performed prior to any preprocessing operations*, including missing value imputation and feature scaling.

All preprocessing steps were fitted *exclusively on the training data*, and the learned parameters were subsequently applied unchanged to both the training and test sets. This ensured that statistical properties of the test data did not influence model training, thereby preventing optimistic bias in supervised evaluation metrics.

=== Model Selection

Three classifier families were selected to represent different learning paradigms:

#figure(
  table(
    columns: 3,
    table.header[*Model*][*Category*][*Rationale*],
    [Logistic Regression], [Linear], [Baseline; interpretable coefficients],
    [Random Forest], [Tree-based], [Nonlinear; feature importance via Gini impurity],
    [k-Nearest Neighbors], [Distance-based], [Instance-based; consistency check against clustering],
  ),
  caption: [Supervised Model Selection],
) <tab:supervised-model-selection>

*Hyperparameter Configuration:*

#figure(
  table(
    columns: 2,
    table.header[*Model*][*Parameters*],
    [Logistic Regression], [`max_iter=1000`, `solver='lbfgs'`],
    [Random Forest], [`n_estimators=100`, `random_state=42`],
    [k-Nearest Neighbors], [`n_neighbors=5`],
  ),
  caption: [Model Hyperparameters],
) <tab:model-hyperparameters>

=== Evaluation Metrics

Performance was quantified using macro-averaged metrics to prevent class imbalance bias:

==== Macro-Averaged Precision, Recall, F1

$
"Precision"_"macro" = 1 / (|C|) sum_(c in C) ("TP"_c) / ("TP"_c + "FP"_c)
$

$
"Recall"_"macro" = 1 / (|C|) sum_(c in C) ("TP"_c) / ("TP"_c + "FN"_c)
$

$
F_1 = (2 times "Precision" times "Recall") / ("Precision" + "Recall")
$

where $C$ is the set of classes and $"TP"$, $"FP"$, $"FN"$ are true positives, false positives, and false negatives respectively.

==== Accuracy

Overall classification correctness was measured as:

$
"Accuracy" = ("TP" + "TN") / ("TP" + "TN" + "FP" + "FN")
$

==== Confusion Matrix

Per-class classification performance was visualized using confusion matrices to identify species-specific misclassification patterns.

=== Feature Importance Extraction

For Random Forest models, feature importance was extracted using Gini impurity:

$
"Importance"(f) = sum_(t in T) Delta G_t dot bb(1)[f_t = f]
$

where $Delta G_t$ is the decrease in Gini impurity at node $t$ when feature $f$ is used for splitting.

*Language Discipline:* Feature importance reflects _associative_ relationships within the dataset. High importance indicates statistical association, not causal influence on resistance phenotype.

=== Stability Across Random Seeds

Model stability was validated across multiple random states to ensure that model performance was not dependent on a specific random initialization:

*Algorithm 4.1: Cross-Seed Stability Check*

*Input:* Dataset D, Model M, Seeds S = {42, 123, 456, 789, 1011}

*Output:* Stability metrics (mean, standard deviation)

For each seed s in S:

    1. Set random state to s

    2. Split D into train/test (80/20, stratified)

    3. Train model M on training set

    4. Evaluate on test set

    5. Record performance metrics

Return: mean(metrics), std(metrics)

Low standard deviation across seeds indicates robust model performance.

=== Phase 3 Output Summary

The output of this phase consists of:

- Classification performance metrics for each model and task
- Confusion matrices for per-class analysis
- Feature importance rankings from Random Forest
- Cross-seed stability statistics

== Phase 4: Integrated Framework Design

An integrated analytical framework was developed to support reproducible, leakage-aware antimicrobial resistance pattern recognition. The framework follows a *three-layer architecture* consisting of a data layer, a processing layer, and a presentation layer.

=== System Architecture

#figure(
  table(
    columns: 3,
    table.header[*Layer*][*Components*][*Function*],
    [Data Layer], [Preprocessing pipeline, feature engineering modules], [Data cleaning, encoding, imputation, feature preparation],
    [Processing Layer], [Clustering, supervised models, statistical analysis], [Pattern discovery, validation, co-resistance analysis],
    [Presentation Layer], [Streamlit dashboard], [Visualization, exploration, and result interpretation],
  ),
  caption: [Integrated Framework Architecture],
) <tab:integrated-framework-architecture>

=== Pipeline Orchestration

Pipeline orchestration was implemented through a *central command-line interface (CLI)* that controlled execution of all analytical stages. This design ensures modularity, reproducibility, and consistent parameter application across experiments.

#figure(
  table(
    columns: 2,
    table.header[*Command*][*Description*],
    [`--pipeline`], [Execute full data preprocessing and clustering pipeline],
    [`--validate`], [Run supervised validation and stability checks],
    [`--analyze`], [Perform post-hoc statistical and regional analyses],
    [`--viz`], [Generate all figures and plots],
    [`--app`], [Launch interactive Streamlit dashboard],
  ),
  caption: [Pipeline Orchestration Commands],
) <tab:pipeline-orchestration-commands>

Reproducibility was enforced using *fixed random seeds*, centralized configuration files, and persistent storage of intermediate artifacts (e.g., linkage matrices, trained models, clustering assignments).

=== Co-Resistance Analysis

Antibiotic co-resistance patterns were quantified using the *phi coefficient (φ)*, calculated from binary resistance co-occurrence tables:

$
phi = (a d - b c) / sqrt((a+b)(c+d)(a+c)(b+d))
$

where $a$, $b$, $c$, and $d$ represent the counts in a 2×2 contingency table of resistance presence and absence between two antibiotics.

#figure(
  table(
    columns: 3,
    table.header[][*Antibiotic B: R*][*Antibiotic B: S*],
    [Antibiotic A: R], [$a$], [$b$],
    [Antibiotic A: S], [$c$], [$d$],
  ),
  caption: [Phi Coefficient Contingency Table Structure],
) <tab:phi-coefficient-contingency-table>

Antibiotic clustering based on co-resistance similarity was subsequently performed using hierarchical clustering with distance defined as $1 - phi$.

=== Interactive Visualization Dashboard

The Streamlit-based dashboard provides interactive exploration of resistance patterns through three primary views:

#figure(
  table(
    columns: 2,
    table.header[*View*][*Description*],
    [Cluster Explorer], [Interactive dendrogram with selectable cut-points; cluster-level resistance heatmaps displaying mean resistance scores per antibiotic],
    [Regional Distribution], [Geographic breakdown of cluster assignments with stacked bar charts showing proportional representation across regions and sites],
    [Co-Resistance Network], [Interactive phi-coefficient heatmap with threshold filtering; hierarchically clustered antibiotic groupings],
    [Isolate Browser], [Individual isolate lookup with complete resistance profile and metadata display],
  ),
  caption: [Dashboard Components],
) <tab:dashboard-components>

The dashboard enables users to:

- Adjust dendrogram cut-height to explore clustering at different granularities
- Filter isolates by region, source type, or species
- Export visualizations and summary statistics
- Compare resistance profiles across selected clusters

== Phase 5: System Evaluation and Interpretation

System performance was evaluated using a combination of *internal clustering metrics*, *supervised validation metrics*, and *controlled association analysis*.

=== Clustering Evaluation Metrics

#figure(
  table(
    columns: 3,
    table.header[*Metric*][*Purpose*][*Interpretation*],
    [Silhouette Score], [Cluster cohesion and separation], [Higher values indicate better-defined clusters],
    [WCSS], [Cluster compactness], [Lower values indicate tighter clusters],
    [Adjusted Rand Index], [Robustness across methods], [Higher values indicate greater stability],
    [Jaccard Coefficient], [Bootstrap stability], [Higher values indicate membership consistency],
    [Cluster Size Distribution], [Practical validity], [Minimum of 20 isolates per cluster],
  ),
  caption: [Clustering Evaluation Metrics],
) <tab:clustering-evaluation-metrics>

=== Supervised Validation Metrics

#figure(
  table(
    columns: 2,
    table.header[*Metric*][*Description*],
    [Accuracy], [Overall classification correctness],
    [Macro Precision], [Average precision across classes],
    [Macro Recall], [Average recall across classes],
    [Macro F1-score], [Balanced performance across classes],
    [Confusion Matrix], [Per-class misclassification analysis],
  ),
  caption: [Supervised Validation Metrics],
) <tab:supervised-validation-metrics>

=== Association Analysis

Associations between resistance clusters and metadata variables were evaluated using *Cramér's V*, computed as:

$
V = sqrt(chi^2 / (n dot min(r-1, c-1)))
$

where $chi^2$ is the chi-square statistic, $n$ is the sample size, and $r$ and $c$ are the dimensions of the contingency table.

#figure(
  table(
    columns: 2,
    table.header[*Cramér's V Value*][*Association Strength*],
    [0.00 – 0.10], [Negligible],
    [0.10 – 0.20], [Weak],
    [0.20 – 0.40], [Moderate],
    [0.40 – 0.60], [Relatively Strong],
    [0.60 – 1.00], [Strong],
  ),
  caption: [Cramér's V Interpretation],
) <tab:cramers-v-interpretation>

=== Interpretation Protocol

Interpretation followed a strict *post-hoc protocol* to maintain analytical integrity:

1. Clusters were generated using resistance features only (Phase 2)
2. Metadata were overlaid after clustering for descriptive analysis
3. Statistical associations were reported using associational language only
4. No causal claims were made regarding resistance emergence or transmission

This protocol ensures that interpretive conclusions remain within the methodological scope of the study.

== Implementation Details

The analytical framework was implemented using *Python 3.9+* and widely adopted open-source scientific computing libraries. Computational requirements were modest and suitable for standard desktop or laptop hardware.

#figure(
  table(
    columns: 2,
    table.header[*Component*][*Specification*],
    [Programming Language], [Python 3.9+],
    [Data Processing], [pandas, numpy],
    [Machine Learning], [scikit-learn],
    [Statistical Analysis], [scipy],
    [Visualization], [matplotlib, seaborn],
    [Dashboard], [Streamlit],
    [Version Control], [Git],
  ),
  caption: [Implementation Environment],
) <tab:implementation-environment>

=== Computational Pipeline

The complete analytical pipeline is summarized in Algorithm 4.2:

*Algorithm 4.2: Complete Analytical Pipeline*

*Input:* Raw AST CSV files

*Output:* Cluster assignments, validation metrics, dashboard

*PHASE 1: Preprocessing*

    1. Load and harmonize data from multiple sources

    2. Parse isolate identifiers to extract metadata

    3. Apply quality filters (70% antibiotic, 30% isolate thresholds)

    4. Encode resistance values (S=0, I=1, R=2)

    5. Impute missing values using median imputation

    6. Compute derived features (MAR, MDR, Resistant Classes)

    7. Separate feature matrix X from metadata matrix M

*PHASE 2: Clustering*

    8. Compute pairwise Euclidean distances

    9. Perform hierarchical clustering (Ward's linkage)

    10. Evaluate k=2 to k=10 using silhouette and WCSS

    11. Apply practical constraints (minimum cluster size)

    12. Select optimal k and assign cluster labels

    13. Assess stability via ARI and bootstrap Jaccard

*PHASE 3: Supervised Validation*

    14. Split data (80/20 stratified, before preprocessing)

    15. Train models (LR, RF, kNN) on training set

    16. Evaluate on test set (accuracy, precision, recall, F1)

    17. Extract feature importance from Random Forest

    18. Repeat across multiple random seeds

*PHASE 4: Analysis and Visualization*

    19. Compute co-resistance phi coefficients

    20. Calculate Cramér's V for cluster-metadata associations

    21. Generate visualizations (dendrograms, heatmaps, bar plots)

    22. Deploy Streamlit dashboard

*Return:* Final cluster assignments, performance metrics, dashboard

== Ethical Considerations

This study involved the secondary analysis of environmental and aquaculture-associated bacterial isolates. No human subjects, clinical samples, or personal identifiers were included in the dataset. The dataset was anonymized prior to analysis, and all results are reported at an aggregate level. Ethical approval was therefore not required for this computational study.

== Limitations

The following methodological limitations are acknowledged:

1. *Scope limitation:* The dataset represents the Water–Fish interface; direct human clinical isolates are not included, limiting generalizability to the full Water–Fish–Human nexus.

2. *Temporal limitation:* The study analyzes a single cross-sectional dataset; temporal dynamics of resistance evolution cannot be assessed.

3. *Imputation effects:* Median imputation may introduce bias for antibiotics with highly skewed resistance distributions.

4. *Clustering assumptions:* Ward's linkage assumes spherical clusters and may not capture non-convex resistance pattern structures.

5. *External validation:* Supervised validation assesses internal discriminative capacity but does not validate against external AMR surveillance datasets.

== Chapter Summary

This chapter presented a *comprehensive, leakage-aware methodology* for antimicrobial resistance pattern recognition using phenotypic AST data. The framework integrates unsupervised discovery, supervised validation, co-resistance analysis, and system-level evaluation while maintaining strict interpretive discipline.

#figure(
  table(
    columns: 3,
    table.header[*Phase*][*Objective Addressed*][*Key Outputs*],
    [Phase 1], [SO1], [Cleaned, encoded, analysis-ready dataset],
    [Phase 2], [SO2 (Part 1)], [Hierarchical resistance clusters with stability assessment],
    [Phase 3], [SO2 (Part 2)], [Supervised validation and stability metrics],
    [Phase 4], [SO3], [Integrated analytical framework and interactive dashboard],
    [Phase 5], [SO4], [Quantitative evaluation and controlled interpretation],
  ),
  caption: [Methodology Summary],
) <tab:methodology-summary>

The methodology ensures that resistance patterns are discovered through objective, data-driven processes and that all interpretive statements remain within appropriate associational bounds. The integrated framework supports reproducible execution and interactive exploration of results.



