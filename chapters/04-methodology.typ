// ============================================
// CHAPTERS/04-METHODOLOGY.TYP
// ============================================

= Methodology

== Research Design

This study adopts an exploratory, computational research design grounded in pattern recognition and machine learning to address the stated research objectives. The design is exploratory because it seeks to uncover latent antimicrobial resistance (AMR) structures that are not explicitly defined by existing categorical labels, rather than testing predefined hypotheses or establishing causal relationships. It is computational in nature because the primary contribution of the study lies in the design, implementation, and evaluation of a data-driven analytical framework for resistance pattern discovery and validation.

The research design integrates unsupervised learning for resistance structure discovery with supervised learning used exclusively as an external validation mechanism. Unsupervised methods are employed to identify resistance patterns based solely on phenotypic similarity in antimicrobial susceptibility testing (AST) data, without incorporating biological, environmental, or geographic labels during the discovery phase. Supervised learning is subsequently applied to assess the discriminative capacity and robustness of the discovered patterns, thereby addressing the limitations of unsupervised clustering when used in isolation.

The methodological strategy follows a staged, leakage-aware pipeline consisting of: (1) data preprocessing and feature engineering, (2) unsupervised resistance pattern discovery, (3) supervised validation, (4) integrated system design, and (5) quantitative evaluation. Throughout the study, strict separation is maintained between pattern discovery and interpretation to prevent information leakage and circular reasoning. The study is associational and descriptive in scope; no biological mechanisms, epidemiological transmission pathways, or clinical outcomes are inferred.

== Data Source and Description

=== Dataset Provenance

The dataset analyzed in this study was generated by the *INOHAC AMR Project Two* research team as part of an environmental antimicrobial resistance surveillance initiative. The present study did not involve primary sampling or laboratory experimentation. All analyses were conducted as a *secondary analysis* of phenotypic AST data collected by the source project.

The dataset comprises AST results for bacterial isolates obtained from environmental and aquaculture-associated sources across three geographic regions in the Philippines. The geographic distribution of isolates is summarized in *Table 4.1*.

#figure(
  table(
    columns: 3,
    table.header[*Region*][*National Code*][*Local Sites*],
    [Eastern Visayas (Ormoc)], [O], [Alegria, Larrazabal],
    [Central Luzon (Pampanga)], [P], [San Gabriel, San Roque],
    [BARMM (Marawi)], [M], [APMC, Dayawan, Gadongan, Tuca Kialdan],
  ),
  caption: [Geographic Distribution of Isolates],
) <tab:geographic-distribution>

=== Sample Source Categories

Isolates originated from environmental matrices representing the *Water–Fish interface* within the broader Water–Fish–Human nexus. These source categories capture exposure pathways relevant to environmental AMR dissemination and were used exclusively as contextual metadata during interpretation. Source categories are listed in *Table 4.2*.

#figure(
  table(
    columns: 3,
    table.header[*Source Code*][*Source Type*][*Description*],
    [DW], [Drinking Water], [Community water sources],
    [LW], [Lake Water], [Natural water bodies],
    [RW], [River Water], [Flowing water systems],
    [EWU], [Effluent Water (Untreated)], [Hospital or facility discharge (Human interface)],
    [EWT], [Effluent Water (Treated)], [Processed effluent discharge (Human interface)],
    [FB, FG, FT, FK], [Fish], [Banak, Gusaw, Tilapia, Kaolang],
  ),
  caption: [Sample Source Categories],
) <tab:sample-source-categories>

*Note:* While direct human clinical isolates are not included, effluent water samples (EWU, EWT) represent the anthropogenic component of the nexus, capturing resistance patterns potentially influenced by human antibiotic use and healthcare facility discharge.

=== Isolate Identification Convention

Each isolate was assigned a structured alphanumeric identifier encoding species, geographic origin, source type, replicate number, and colony number using the format:

```
[Species Prefix]_[Region][Site][Source][Replicate]C[Colony]
```

This convention enables systematic metadata parsing while preserving traceability throughout the analytical pipeline.

=== Antimicrobial Panel

Phenotypic AST data were generated using a panel of *22 antibiotics spanning 12 antimicrobial classes*, including an ESBL screening indicator. The antimicrobial panel is summarized in *Table 4.3*.

#figure(
  table(
    columns: 2,
    table.header[*Antimicrobial Class*][*Antibiotics*],
    [Penicillins], [Ampicillin],
    [β-lactam/β-lactamase inhibitors], [Amoxicillin/Clavulanic Acid],
    [Cephalosporins (1st gen.)], [Cefalexin, Cefalotin],
    [Cephalosporins (3rd/4th gen.)], [Cefpodoxime, Cefotaxime, Cefovecin, Ceftiofur],
    [Advanced cephalosporins], [Ceftaroline, Ceftazidime/Avibactam],
    [Carbapenems], [Imipenem],
    [Aminoglycosides], [Amikacin, Gentamicin, Neomycin],
    [Quinolones / Fluoroquinolones], [Nalidixic Acid, Enrofloxacin, Marbofloxacin, Pradofloxacin],
    [Tetracyclines], [Doxycycline, Tetracycline],
    [Nitrofurans], [Nitrofurantoin],
    [Phenicols], [Chloramphenicol],
    [Folate pathway inhibitors], [Trimethoprim/Sulfamethoxazole],
    [Resistance indicator], [ESBL screening],
  ),
  caption: [Antimicrobial Panel Composition],
) <tab:antimicrobial-panel>

== Phase 1: Data Preprocessing and Feature Engineering

The objective of this phase is to transform heterogeneous raw antimicrobial susceptibility testing (AST) records into a structured numerical form that supports similarity-based analysis while preserving biologically meaningful resistance information. All preprocessing decisions were explicitly parameterized to ensure reproducibility and to prevent information leakage in downstream analyses.

=== Data Ingestion and Harmonization

Raw phenotypic AST data were consolidated from multiple source files provided by the INOHAC–Project 2. These files, supplied as comma-separated value (CSV) datasets corresponding to different collection sites, were integrated into a single unified dataset.

The ingestion process included the following steps:

- *Schema harmonization:* Column names, data types, and value encodings were standardized across source files to ensure structural consistency.
- *Metadata extraction:* Structured isolate identifiers were parsed to extract contextual variables such as geographic region, local site, source category, replicate number, and colony number.
- *Duplicate resolution:* Duplicate isolate records were identified and removed to ensure a one-to-one correspondence between isolates and resistance profiles.

This step ensured that all downstream analyses operated on a coherent and internally consistent dataset.

=== Data Quality Filtering

To ensure sufficient data completeness for reliable pattern recognition, threshold-based filtering criteria were applied at both the antibiotic and isolate levels.

- *Antibiotic-level filtering:* Antibiotics tested on fewer than *70% of isolates* were excluded to ensure adequate representation across resistance profiles.
- *Isolate-level filtering:* Isolates with more than *30% missing susceptibility values* were removed to avoid excessive reliance on imputation.

These thresholds balance data retention with analytical reliability and are consistent with exploratory machine learning practices applied to high-dimensional biological data. All thresholds were fixed prior to analysis to prevent post-hoc optimization.

=== Resistance Encoding

Phenotypic AST outcomes recorded as categorical values—Susceptible (S), Intermediate (I), and Resistant (R)—were converted into ordinal numerical representations to support quantitative analysis.

#figure(
  table(
    columns: 3,
    table.header[*Phenotype*][*Encoded Value*][*Interpretation*],
    [Susceptible (S)], [0], [No resistance observed],
    [Intermediate (I)], [1], [Reduced susceptibility],
    [Resistant (R)], [2], [Clinical resistance],
  ),
  caption: [Ordinal Encoding of Phenotypic AST Results],
) <tab:resistance-encoding>

This ordinal encoding preserves the progressive nature of resistance severity while enabling distance-based computations.

=== Missing Value Imputation

Following threshold-based exclusion, remaining missing susceptibility values were imputed using *median imputation*, applied independently to each antibiotic feature:

$
hat(x)_(i,j) = "median"({x_(k,j) | x_(k,j) "is observed"})
$

where $hat(x)_(i,j)$ is the imputed resistance value for isolate $i$ and antibiotic $j$, and $x_(k,j)$ represents observed resistance values for antibiotic $j$.

Median imputation is robust to outliers and preserves the ordinal nature of resistance data. Alternative strategies such as mean or mode imputation were considered; however, the median provides a conservative central estimate suitable for exploratory pattern recognition.

=== Derived Resistance Feature Computation

To support downstream interpretation and epidemiological contextualization, several derived resistance descriptors were computed. These features were *not included as inputs* to unsupervised clustering to prevent bias during pattern discovery.

==== Multiple Antibiotic Resistance (MAR) Index

The MAR index quantifies the proportion of antibiotics to which an isolate exhibits resistance:

$
"MAR" = a / b
$

where $a$ is the number of antibiotics for which resistance is observed (encoded value = 2), and $b$ is the total number of antibiotics tested for the isolate.

*Interpretation:*

- MAR ≤ 0.2: Low-risk source
- MAR > 0.2: High-risk source, indicative of antibiotic selection pressure

(Reference: Krumperman, 1983)

==== Resistant Classes Count

The breadth of resistance across antimicrobial classes was computed as:

$
"Resistant Classes" = |{c | exists a in c, "resistance"(a) = "true"}|
$

where $c$ denotes an antimicrobial class and $a$ denotes an antibiotic belonging to that class.

This metric captures class-level resistance diversity rather than resistance to individual agents.

==== Multidrug Resistance (MDR) Classification

An isolate was classified as multidrug-resistant (MDR) if resistance was observed in *three or more antimicrobial classes*, consistent with established definitions:

$
"MDR" = cases(
  1\, & "if Resistant Classes" >= 3,
  0\, & "otherwise"
)
$

(Reference: Magiorakos et al., 2012)

=== Feature–Metadata Separation

To prevent *information leakage* and circular reasoning, the analysis-ready dataset was explicitly partitioned into two components:

- *Feature Matrix ($bold(X)$):* Encoded resistance values for the 22 antibiotics, used exclusively for unsupervised clustering and supervised validation.
- *Metadata Matrix ($bold(M)$):* Contextual variables (e.g., region, site, species, source category, MDR status), reserved solely for post-discovery interpretation.

This separation ensures that resistance patterns are discovered strictly from phenotypic similarity and are not influenced by external labels or contextual information.

=== Phase 1 Output Summary

The output of Phase 1 consists of:

- Analysis-ready resistance feature matrix with encoded susceptibility values
- Derived resistance indicators (MAR, Resistant Classes, MDR status)
- Separated metadata matrix for post-hoc interpretation
- Data quality documentation including filtering statistics

== Phase 2: Unsupervised Structure Discovery

The objective of this phase is to identify latent resistance structures based solely on phenotypic similarity in antimicrobial susceptibility profiles, without incorporating predefined biological, environmental, or geographic labels. All analyses in this phase operate exclusively on the resistance feature matrix produced in Phase 1.

=== Clustering Algorithm Selection

*Hierarchical Agglomerative Clustering (HAC)* was selected as the primary unsupervised learning method due to the following properties:

- *Exploratory suitability:* HAC does not require prior specification of the number of clusters, aligning with the study's objective of discovering latent structure rather than fitting predefined categories.
- *Multi-scale structure discovery:* The hierarchical representation enables examination of resistance patterns at multiple levels of granularity.
- *Interpretability:* Dendrograms provide transparent visualization of cluster formation and merge decisions.
- *Minimal structural assumptions:* HAC does not impose assumptions regarding cluster shape or distribution.

These characteristics make HAC appropriate for exploratory pattern recognition in high-dimensional resistance data.

=== Distance Metric

Euclidean distance was used as the primary measure of dissimilarity between resistance profiles:

$
d(x, y) = sqrt(sum_(i=1)^n (x_i - y_i)^2)
$

where $x$ and $y$ are resistance vectors for two isolates and $n$ is the number of antibiotics.

*Justification:* Euclidean distance preserves proportional differences introduced by ordinal resistance encoding (S = 0, I = 1, R = 2) and is required for variance-based linkage methods such as Ward's criterion. Given the 22-dimensional feature space where the number of features is substantially smaller than the sample size, Euclidean distance remains effective without dimensionality reduction.

=== Linkage Method

Ward's *minimum variance linkage method* was used to guide cluster merging:

$
Delta(A, B) = (n_A n_B) / (n_A + n_B) norm(c_A - c_B)^2
$

where:

- $n_A$ and $n_B$ denote the sizes of clusters $A$ and $B$,
- $c_A$ and $c_B$ represent their respective centroids.

Ward's method minimizes the increase in total within-cluster variance at each merge step, producing compact and relatively balanced clusters. This property is advantageous for identifying resistance phenotypes that are internally coherent and externally separable in feature space.

=== Determination of the Number of Clusters

The optimal number of clusters was determined using a *data-driven, multi-criteria approach* combining quantitative metrics with practical constraints.

==== Silhouette Analysis

Cluster cohesion and separation were evaluated using the silhouette score:

$
s(i) = (b(i) - a(i)) / max(a(i), b(i))
$

where:

- $a(i)$ is the mean intra-cluster distance for isolate $i$,
- $b(i)$ is the mean distance to the nearest neighboring cluster.

Higher silhouette values indicate better-defined cluster structure. The average silhouette score across all isolates was computed for cluster solutions ranging from $k = 2$ to $k = 10$.

==== Within-Cluster Sum of Squares (WCSS)

Cluster compactness was assessed using the within-cluster sum of squares:

$
"WCSS" = sum_(k=1)^K sum_(x in C_k) norm(x - mu_k)^2
$

where $C_k$ denotes cluster $k$ and $mu_k$ its centroid. The elbow method was used to identify diminishing returns in compactness as the number of clusters increased.

==== Practical Constraints

To ensure analytical stability and interpretability, additional constraints were applied:

- *Minimum cluster size:* At least *20 isolates per cluster*
- *Interpretability:* Preference for solutions that balance granularity with conceptual clarity, avoiding over-fragmentation

The final cluster solution was selected based on convergence across these criteria rather than optimization of a single metric.

=== Cluster Stability Assessment

The robustness of the discovered clustering structure was evaluated through *stability analysis* using two complementary approaches.

==== Alternative Configuration Comparison

Agreement between clustering solutions obtained using different distance metrics (Euclidean, Manhattan) was quantified using the *Adjusted Rand Index (ARI)*:

$
"ARI" = ("RI" - E["RI"]) / (max("RI") - E["RI"])
$

where RI is the Rand Index and $E["RI"]$ is its expected value under random labeling, and $max("RI")$ is the maximum possible Rand Index.

==== Bootstrap Stability

Cluster membership stability was assessed through bootstrap resampling:

1. Resample 80% of isolates with replacement ($n = 100$ iterations)
2. Re-cluster each bootstrap sample using identical parameters
3. Compute Jaccard similarity between original and bootstrap cluster assignments

Higher ARI and Jaccard values indicate greater stability and robustness of the clustering structure, suggesting that identified resistance patterns are not artifacts of specific parameter choices.

=== Cluster-Level Profile Characterization

For each identified cluster, a *resistance profile* was computed summarizing the dominant phenotypic characteristics:

- *Mean resistance score* per antibiotic (0–2 scale)
- *Resistance prevalence* (proportion of isolates with R classification per antibiotic)
- *Class-level resistance summary* aggregating across antimicrobial categories

These profiles enable qualitative characterization of each cluster's resistance signature.

=== Phase 2 Output Summary

The output of this phase consists of:

- Final cluster assignments for each isolate
- Hierarchical linkage matrices and dendrograms
- Cluster-level resistance profiles summarizing dominant phenotypic patterns
- Stability metrics (ARI, Jaccard coefficients)

These outputs form the basis for supervised validation and interpretation, while remaining independent of external biological or contextual labels during discovery.

== Phase 3: Supervised Validation

Supervised learning models were used solely to validate the discriminative capacity of the discovered resistance patterns. This phase implements leakage-safe train–test splitting, macro-averaged evaluation metrics, confusion matrix analysis, feature importance extraction, and cross-seed stability checks.

=== Classification Tasks

Two supervised classification tasks were designed to assess whether resistance patterns align with known biological categories:

#figure(
  table(
    columns: 3,
    table.header[*Task*][*Target Variable*][*Purpose*],
    [Species Discrimination], [Bacterial species], [Assess if resistance fingerprints distinguish species],
    [MDR Classification], [MDR status (0/1)], [Validate resistance-MDR relationship],
  ),
  caption: [Supervised Classification Tasks],
) <tab:supervised-classification-tasks>

=== Leakage-Safe Data Splitting

To prevent information leakage between training and evaluation phases, the dataset was first partitioned into *training (80%) and test (20%) subsets* using stratified sampling to preserve class distributions. *Train–test splitting was performed prior to any preprocessing operations*, including missing value imputation and feature scaling.

All preprocessing steps were fitted *exclusively on the training data*, and the learned parameters were subsequently applied unchanged to both the training and test sets. This ensured that statistical properties of the test data did not influence model training, thereby preventing optimistic bias in supervised evaluation metrics.

=== Model Selection

Three classifier families were selected to represent different learning paradigms:

#figure(
  table(
    columns: 3,
    table.header[*Model*][*Category*][*Rationale*],
    [Logistic Regression], [Linear], [Baseline; interpretable coefficients],
    [Random Forest], [Tree-based], [Nonlinear; feature importance via Gini impurity],
    [k-Nearest Neighbors], [Distance-based], [Instance-based; consistency check against clustering],
  ),
  caption: [Supervised Model Selection],
) <tab:supervised-model-selection>

*Hyperparameter Configuration:*

#figure(
  table(
    columns: 2,
    table.header[*Model*][*Parameters*],
    [Logistic Regression], [`max_iter=1000`, `solver='lbfgs'`],
    [Random Forest], [`n_estimators=100`, `random_state=42`],
    [k-Nearest Neighbors], [`n_neighbors=5`],
  ),
  caption: [Model Hyperparameters],
) <tab:model-hyperparameters>

=== Evaluation Metrics

Performance was quantified using macro-averaged metrics to prevent class imbalance bias:

==== Macro-Averaged Precision, Recall, F1

$
"Precision"_"macro" = 1 / (|C|) sum_(c in C) ("TP"_c) / ("TP"_c + "FP"_c)
$

$
"Recall"_"macro" = 1 / (|C|) sum_(c in C) ("TP"_c) / ("TP"_c + "FN"_c)
$

$
F_1 = (2 times "Precision" times "Recall") / ("Precision" + "Recall")
$

where $C$ is the set of classes and $"TP"$, $"FP"$, $"FN"$ are true positives, false positives, and false negatives respectively.

==== Accuracy

Overall classification correctness was measured as:

$
"Accuracy" = ("TP" + "TN") / ("TP" + "TN" + "FP" + "FN")
$

==== Confusion Matrix

Per-class classification performance was visualized using confusion matrices to identify species-specific misclassification patterns.

=== Feature Importance Extraction

For Random Forest models, feature importance was extracted using Gini impurity:

$
"Importance"(f) = sum_(t in T) Delta G_t dot bb(1)[f_t = f]
$

where $Delta G_t$ is the decrease in Gini impurity at node $t$ when feature $f$ is used for splitting.

*Language Discipline:* Feature importance reflects _associative_ relationships within the dataset. High importance indicates statistical association, not causal influence on resistance phenotype.

=== Stability Across Random Seeds

Model stability was validated across multiple random states to ensure that model performance was not dependent on a specific random initialization:

*Algorithm 4.1: Cross-Seed Stability Check*

*Input:* Dataset D, Model M, Seeds S = {42, 123, 456, 789, 1011}

*Output:* Stability metrics (mean, standard deviation)

For each seed s in S:

    1. Set random state to s

    2. Split D into train/test (80/20, stratified)

    3. Train model M on training set

    4. Evaluate on test set

    5. Record performance metrics

Return: mean(metrics), std(metrics)

Low standard deviation across seeds indicates robust model performance.

=== Phase 3 Output Summary

The output of this phase consists of:

- Classification performance metrics for each model and task
- Confusion matrices for per-class analysis
- Feature importance rankings from Random Forest
- Cross-seed stability statistics



